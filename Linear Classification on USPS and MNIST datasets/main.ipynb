{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/ektakatiyar/Downloads/ML/Project3/mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "print(\"training_data: \"+ str(training_data[1][0]))\n",
    "print(\"validation_data: \"+ str(validation_data[1][0]))\n",
    "print(\"test_data: \"+ str(test_data[1][0]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label = np.zeros((50000, 10))\n",
    "training_label[np.arange(50000), training_data[1]] = 1\n",
    "print(training_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_label=np.zeros((10000, 10))\n",
    "validation_label[np.arange(10000), validation_data[1]] = 1\n",
    "print(validation_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = np.zeros((10000,10))\n",
    "test_label[np.arange(10000),test_data[1]]=1\n",
    "print(test_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, weights):\n",
    "    print(\"Feature shape :\"+ str(features.shape))\n",
    "    #print(\"Weights shape :\"+ str(weights.shape))\n",
    "    x = np.dot(features, weights)\n",
    "    return softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    sum_ex = np.sum( np.exp(x))\n",
    "    return ex/sum_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(features, labels, weights):\n",
    "    '''\n",
    "    Using Mean Absolute Error\n",
    "\n",
    "    Features:(100,3)\n",
    "    Labels: (100,1)\n",
    "    Weights:(3,1)\n",
    "    Returns 1D matrix of predictions\n",
    "    Cost = ( log(predictions) + (1-labels)*log(1-predictions) ) / len(labels)\n",
    "    '''\n",
    "    observations = len(labels)\n",
    "\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #Take the error when label=1\n",
    "    class1_cost = -labels*np.log(predictions)\n",
    "\n",
    "    #Take the error when label=0\n",
    "    class2_cost = (1-labels)*np.log(1-predictions)\n",
    "\n",
    "    #Take the sum of both costs\n",
    "    cost = class1_cost - class2_cost\n",
    "\n",
    "    #Take the average cost\n",
    "    cost = cost.sum()/observations\n",
    "    print(\"Cost: \"+str(cost))\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(features, labels, weights, lr):\n",
    "    '''\n",
    "    Vectorized Gradient Descent\n",
    "\n",
    "    Features:(200, 3)\n",
    "    Labels: (200, 1)\n",
    "    Weights:(3, 1)\n",
    "    '''\n",
    "    N = len(features)\n",
    "\n",
    "    #1 - Get Predictions\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #2 Transpose features from (200, 3) to (3, 200)\n",
    "    # So we can multiply w the (200,1)  cost matrix.\n",
    "    # Returns a (3,1) matrix holding 3 partial derivatives --\n",
    "    # one for each feature -- representing the aggregate\n",
    "    # slope of the cost function across all observations\n",
    "    gradient = np.dot(features.T,  predictions - labels)\n",
    "\n",
    "    #3 Take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "\n",
    "    #4 - Multiply the gradient by our learning rate\n",
    "    gradient *= lr\n",
    "\n",
    "    #5 - Subtract from our weights to minimize cost\n",
    "    weights -= gradient\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, labels, weights, lr, iters):\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        weights = update_weights(features, labels, weights, lr)\n",
    "\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Log Progress\n",
    "        if i % 1000 == 0:\n",
    "            print (\"iter: \"+str(i) + \" cost: \"+str(cost))\n",
    "\n",
    "    return weights, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_model(predicted_labels, actual_labels):\n",
    "    count=0\n",
    "    print(\"predicted_labels :\"+ str(predicted_labels.shape))\n",
    "    print(\"actual_labels :\"+ str(actual_labels.shape))\n",
    "    for i in range(len(predicted_labels)):\n",
    "        if np.around(predicted_labels[i])==actual_labels[i]:\n",
    "            count=count+1;\n",
    "    accuracy= (count/len(predicted_labels))*100\n",
    "    print(\"Accuracy: \"+ str(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training model for different hyperparameters RawData, RawTarget, Weights, learning rate, epochs\n",
    "weights,cost=train(RawData,RawTarget,np.zeros((RawData.shape[1],1)),0.002,100)\n",
    "Cost_function=cost_function(RawData,RawTarget,0)\n",
    "predictedVal=predict(RawData,weights)\n",
    "print(\"predictedVal :\"+str(predictedVal.shape))\n",
    "Model_accuracy=accuracy_model(predict(RawData,weights),RawTarget)\n",
    "print(\"Cost_function :\"+str(Cost_function))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
